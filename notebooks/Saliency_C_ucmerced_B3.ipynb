{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03a5eee0",
      "metadata": {
        "id": "03a5eee0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D,Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z_fBqr5MXzf9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_fBqr5MXzf9",
        "outputId": "de8ae77a-2bed-4101-8c20-e3e6791d5430"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6caae4c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6caae4c4",
        "outputId": "f79906ac-b371-4dda-bebc-f5d6dd2443b7"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 1. CARGA Y PROCESAMIENTO DEL DATASET\n",
        "# ================================\n",
        "\n",
        "dataset_path = r\"/content/drive/MyDrive/UCMerced_LandUse/Images\"\n",
        "nclases = 21\n",
        "img_size = (256, 256)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "clase_dict = {}\n",
        "\n",
        "for idx, clase in enumerate(sorted(os.listdir(dataset_path))):\n",
        "    clase_path = os.path.join(dataset_path, clase)\n",
        "    if os.path.isdir(clase_path):\n",
        "        clase_dict[idx] = clase\n",
        "        for img_name in os.listdir(clase_path):\n",
        "            img_path = os.path.join(clase_path, img_name)\n",
        "            try:\n",
        "                img = Image.open(img_path).convert('RGB')\n",
        "                img = img.resize(img_size)\n",
        "                img_array = np.array(img)\n",
        "                X.append(img_array)\n",
        "                y.append(idx)\n",
        "            except Exception as e:\n",
        "                print(f\"Error cargando imagen {img_path}: {e}\")\n",
        "\n",
        "X = np.array(X).astype('float32') / 255.0\n",
        "y = np.array(y)\n",
        "\n",
        "# Divisi√≥n 80-10-10\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# One-hot encoding\n",
        "y_train_cat = to_categorical(y_train, nclases)\n",
        "y_val_cat = to_categorical(y_val, nclases)\n",
        "y_test_cat = to_categorical(y_test, nclases)\n",
        "\n",
        "print(f\"Training data shape: {X_train.shape}, {y_train_cat.shape}\")\n",
        "print(f\"Validation data shape: {X_val.shape}, {y_val_cat.shape}\")\n",
        "print(f\"Test data shape: {X_test.shape}, {y_test_cat.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edb8648c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edb8648c",
        "outputId": "2d49025a-b9e1-43fc-d2c4-f86fc48cf08e"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 2. DEFINICI√ìN DEL MODELO CNN\n",
        "# ================================\n",
        "\n",
        "cnn = Sequential([\n",
        "    # Bloque 1\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same',\n",
        "           input_shape=(256, 256, 3),\n",
        "           kernel_regularizer=regularizers.l2(0.0005)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same',\n",
        "           kernel_regularizer=regularizers.l2(0.0005)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    # Bloque 2\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same',\n",
        "           kernel_regularizer=regularizers.l2(0.0005)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same',\n",
        "           kernel_regularizer=regularizers.l2(0.0005)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    # Bloque 3\n",
        "    Conv2D(256, (3, 3), activation='relu', padding='same',\n",
        "           kernel_regularizer=regularizers.l2(0.0005)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(256, (3, 3), activation='relu', padding='same',\n",
        "           kernel_regularizer=regularizers.l2(0.0005)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    # Global Average Pooling en vez de Flatten\n",
        "    GlobalAveragePooling2D(),\n",
        "\n",
        "    # Capas densas\n",
        "    Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(21, activation='softmax')\n",
        "])\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "cnn.compile(optimizer=optimizer,\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# ================================\n",
        "# 3. ENTRENAMIENTO DEL MODELO\n",
        "# ================================\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=25,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=12,\n",
        "    min_lr=0.00001\n",
        ")\n",
        "\n",
        "history = cnn.fit(\n",
        "    datagen.flow(X_train, y_train_cat, batch_size=32),\n",
        "    validation_data=(X_val, y_val_cat),\n",
        "    epochs=500,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c8ab029",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c8ab029",
        "outputId": "73c262d2-dbf1-4bcc-8bcd-f5ffae621a32"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 4. EVALUACI√ìN DEL MODELO\n",
        "# ================================\n",
        "\n",
        "train_loss, train_accuracy = cnn.evaluate(X_train, y_train_cat)\n",
        "val_loss, val_accuracy = cnn.evaluate(X_val, y_val_cat)\n",
        "test_loss, test_accuracy = cnn.evaluate(X_test, y_test_cat)\n",
        "\n",
        "print(f\"\\nTraining Accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ff52a65",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "6ff52a65",
        "outputId": "e292f138-8d31-4b5f-8925-05443353696a"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 5. GR√ÅFICAS DE ENTRENAMIENTO\n",
        "# ================================\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f71a3930",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f71a3930",
        "outputId": "5f907d01-4737-49c6-f775-6cf83d6821ad"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 6. MATRIZ DE CONFUSI√ìN DATOS DE TESTEO\n",
        "# ================================\n",
        "\n",
        "y_pred = np.argmax(cnn.predict(X_test), axis=-1)\n",
        "y_true = np.argmax(y_test_cat, axis=-1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(15, 12))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=list(clase_dict.values()),\n",
        "            yticklabels=list(clase_dict.values()))\n",
        "plt.title('CONFUSION MATRIX TEST DATA - UC Merced Dataset')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52630232",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "52630232",
        "outputId": "5efedbc6-86b9-4027-dad1-3fc793484247"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 7. MATRIZ DE CONFUSI√ìN DATOS DE VALIDACI√ìN\n",
        "# ================================\n",
        "\n",
        "y_pred = np.argmax(cnn.predict(X_val), axis=-1)\n",
        "y_true = np.argmax(y_val_cat, axis=-1)\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=list(clase_dict.values()),\n",
        "            yticklabels=list(clase_dict.values()))\n",
        "plt.title('CONFUSION MATRIX VALIDATION DATA - UC Merced Dataset')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VsDypRuHYDDl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VsDypRuHYDDl",
        "outputId": "b753e911-521c-49c4-d878-0affb8a634e2"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 7. MATRIZ DE CONFUSI√ìN DATOS DE ENTRENAMIENTO\n",
        "# ================================\n",
        "\n",
        "y_pred = np.argmax(cnn.predict(X_train), axis=-1)\n",
        "y_true = np.argmax(y_train_cat, axis=-1)\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=list(clase_dict.values()),\n",
        "            yticklabels=list(clase_dict.values()))\n",
        "plt.title('CONFUSION MATRIX TRAIN DATA - UC Merced Dataset')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "663cfeb8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "663cfeb8",
        "outputId": "f4700e7d-bfab-4bc2-af63-f74d50598bc2"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 7. PRECISI√ìN POR CLASE\n",
        "# ================================\n",
        "\n",
        "print(\"\\nAccuracy por clase:\")\n",
        "for i in range(nclases):\n",
        "    mask = (y_true == i)\n",
        "    if np.sum(mask) > 0:\n",
        "        acc = accuracy_score(y_true[mask], y_pred[mask])\n",
        "        print(f\"{clase_dict[i]}: {acc*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Cz8-aop7kMM1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cz8-aop7kMM1",
        "outputId": "a715e1bc-ecda-42ac-fd3b-9a4a2a10e93f"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = np.argmax(cnn.predict(X_val), axis=-1)\n",
        "y_true = np.argmax(y_val_cat, axis=-1)\n",
        "\n",
        "print(classification_report(\n",
        "    y_true, y_pred,\n",
        "    target_names=list(clase_dict.values())\n",
        "))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IhPokBnqmiS1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "IhPokBnqmiS1",
        "outputId": "03e5d978-e310-4390-8706-1a485f41f8c6"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 8. MAPA DE SALIENCIA (EXPLICACI√ìN DEL MODELO)\n",
        "# ================================\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def generar_mapa_saliencia(modelo, imagen, etiqueta_real, clases):\n",
        "    \"\"\"\n",
        "    Genera y muestra el mapa de saliencia para una imagen dada,\n",
        "    explicando qu√© regiones influyeron m√°s en la predicci√≥n del modelo.\n",
        "    \"\"\"\n",
        "\n",
        "    # Aseguramos que la imagen tenga el formato correcto (batch de 1)\n",
        "    img_tensor = tf.convert_to_tensor(imagen[np.newaxis, ...])\n",
        "\n",
        "    # Calculamos los gradientes respecto a la entrada\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(img_tensor)\n",
        "        predicciones = modelo(img_tensor)\n",
        "        clase_predicha = tf.argmax(predicciones[0])\n",
        "        score = predicciones[:, clase_predicha]\n",
        "\n",
        "    # Gradientes del score con respecto a la imagen de entrada\n",
        "    gradientes = tape.gradient(score, img_tensor)\n",
        "\n",
        "    # Tomamos el valor absoluto y combinamos canales RGB (m√°ximo)\n",
        "    saliencia = tf.reduce_max(tf.abs(gradientes), axis=-1)[0]\n",
        "\n",
        "    # Normalizamos entre 0 y 1\n",
        "    saliencia = (saliencia - tf.reduce_min(saliencia)) / (tf.reduce_max(saliencia) + 1e-8)\n",
        "\n",
        "    # Visualizaci√≥n\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(imagen)\n",
        "    plt.title(f'Imagen Original\\nClase real: {clases[etiqueta_real]}')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(imagen)\n",
        "    plt.imshow(saliencia, cmap='plasma', alpha=0.5)\n",
        "    plt.title(f'Mapa de Saliencia\\nPredicci√≥n: {clases[int(clase_predicha)]}')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ================================\n",
        "# Ejemplo de uso del mapa de saliencia\n",
        "# ================================\n",
        "\n",
        "# Selecciona un √≠ndice del conjunto de prueba\n",
        "indice = 50\n",
        "\n",
        "imagen_ejemplo = X_test[indice]\n",
        "etiqueta_real = np.argmax(y_test_cat[indice])\n",
        "\n",
        "generar_mapa_saliencia(cnn, imagen_ejemplo, etiqueta_real, clase_dict)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CgftBYxZAd_e",
      "metadata": {
        "id": "CgftBYxZAd_e"
      },
      "source": [
        "Versi√≥n 1: Mejora visual del mapa de saliencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A_VvvH1FAC9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "A_VvvH1FAC9f",
        "outputId": "226943b3-5cda-4a4b-c80d-bfe730aedcbc"
      },
      "outputs": [],
      "source": [
        "def generar_mapa_saliencia_mejorado(modelo, imagen, etiqueta_real):\n",
        "    \"\"\"\n",
        "    Genera un mapa de saliencia con mejor visualizaci√≥n (tipo heatmap intensivo).\n",
        "    \"\"\"\n",
        "    img_tensor = tf.convert_to_tensor(imagen[np.newaxis, ...])\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(img_tensor)\n",
        "        predicciones = modelo(img_tensor)\n",
        "        clase_predicha = tf.argmax(predicciones[0])\n",
        "        score = predicciones[:, clase_predicha]\n",
        "\n",
        "    gradientes = tape.gradient(score, img_tensor)\n",
        "    saliencia = tf.reduce_max(tf.abs(gradientes), axis=-1)[0]\n",
        "\n",
        "    # Normalizaci√≥n con realce gamma\n",
        "    saliencia = (saliencia - tf.reduce_min(saliencia)) / (tf.reduce_max(saliencia) + 1e-8)\n",
        "    saliencia = tf.pow(saliencia, 0.5)  # realza √°reas calientes\n",
        "\n",
        "    # Conversi√≥n a RGB heatmap tipo GradCAM\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(imagen)\n",
        "    plt.title(f'Clase real: {clase_dict[etiqueta_real]}')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(imagen)\n",
        "    plt.imshow(saliencia, cmap='jet', alpha=0.55)\n",
        "    plt.title(f'Mapa de Saliencia Mejorado\\nPredicci√≥n: {clase_dict[int(clase_predicha)]}')\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "indice = 20\n",
        "imagen_ejemplo = X_test[indice]\n",
        "etiqueta_real = np.argmax(y_test_cat[indice])\n",
        "\n",
        "# Versi√≥n mejorada (sin Grad-CAM):\n",
        "generar_mapa_saliencia_mejorado(cnn, imagen_ejemplo, etiqueta_real)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ThnSjArzB2JT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ThnSjArzB2JT",
        "outputId": "a7e4d5f1-630d-408c-b36c-64c92405575b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "def generar_mapa_saliencia_mejorado(modelo, imagen, etiqueta_real, clase_dict):\n",
        "    \"\"\"\n",
        "    Genera un mapa de saliencia con mejor visualizaci√≥n (tipo heatmap intensivo).\n",
        "    Retorna la imagen original y el mapa para graficarlos externamente.\n",
        "    \"\"\"\n",
        "    img_tensor = tf.convert_to_tensor(imagen[np.newaxis, ...])\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(img_tensor)\n",
        "        predicciones = modelo(img_tensor)\n",
        "        clase_predicha = tf.argmax(predicciones[0])\n",
        "        score = predicciones[:, clase_predicha]\n",
        "\n",
        "    gradientes = tape.gradient(score, img_tensor)\n",
        "    saliencia = tf.reduce_max(tf.abs(gradientes), axis=-1)[0]\n",
        "\n",
        "    # üî• Normalizaci√≥n con realce gamma (mejor contraste)\n",
        "    saliencia = (saliencia - tf.reduce_min(saliencia)) / (tf.reduce_max(saliencia) + 1e-8)\n",
        "    saliencia = tf.pow(saliencia, 0.5)\n",
        "\n",
        "    return saliencia.numpy(), int(clase_predicha)\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# üîß Mostrar una imagen por clase (2 por fila)\n",
        "# =========================================\n",
        "\n",
        "num_clases = len(clase_dict)\n",
        "cols = 2\n",
        "rows = int(np.ceil(num_clases))  # una clase por par (original + saliencia)\n",
        "\n",
        "plt.figure(figsize=(10, 5 * rows))\n",
        "\n",
        "for i in range(num_clases):\n",
        "    # Encuentra el primer ejemplo de esa clase\n",
        "    idx = np.where(np.argmax(y_test_cat, axis=1) == i)[0][0]\n",
        "    imagen = X_test[idx]\n",
        "    etiqueta_real = i\n",
        "\n",
        "    # Generar mapa de saliencia\n",
        "    saliencia, clase_predicha = generar_mapa_saliencia_mejorado(cnn, imagen, etiqueta_real, clase_dict)\n",
        "\n",
        "    # --- Imagen original ---\n",
        "    plt.subplot(rows, cols, 2*i + 1)\n",
        "    plt.imshow(imagen)\n",
        "    plt.title(f\"Real: {clase_dict[etiqueta_real]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # --- Imagen con heatmap ---\n",
        "    plt.subplot(rows, cols, 2*i + 2)\n",
        "    plt.imshow(imagen)\n",
        "    plt.imshow(saliencia, cmap='jet', alpha=0.55)\n",
        "    plt.title(f\"Pred: {clase_dict[clase_predicha]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cC5W5DqTF-ir",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC5W5DqTF-ir",
        "outputId": "e5f45150-e07d-42cd-c16a-9e2f9749d814"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# === Funci√≥n para generar mapa de saliencia mejorado ===\n",
        "def generar_mapa_saliencia_mejorado(modelo, imagen, etiqueta_real, clase_dict):\n",
        "    \"\"\"\n",
        "    Genera un mapa de saliencia tipo heatmap con mejor contraste visual.\n",
        "    Devuelve el mapa y la clase predicha.\n",
        "    \"\"\"\n",
        "    img_tensor = tf.convert_to_tensor(imagen[np.newaxis, ...])\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(img_tensor)\n",
        "        predicciones = modelo(img_tensor)\n",
        "        clase_predicha = tf.argmax(predicciones[0])\n",
        "        score = predicciones[:, clase_predicha]\n",
        "\n",
        "    gradientes = tape.gradient(score, img_tensor)\n",
        "    saliencia = tf.reduce_max(tf.abs(gradientes), axis=-1)[0]\n",
        "\n",
        "    # Normalizaci√≥n + realce gamma (mejora visibilidad)\n",
        "    saliencia = (saliencia - tf.reduce_min(saliencia)) / (tf.reduce_max(saliencia) + 1e-8)\n",
        "    saliencia = tf.pow(saliencia, 0.5)\n",
        "\n",
        "    return saliencia, int(clase_predicha)\n",
        "\n",
        "# === üìÇ Ruta personalizada en tu Google Drive ===\n",
        "output_dir = \"/content/drive/MyDrive/Saliency_Maps\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# === Generar mapa de saliencia para una imagen por clase ===\n",
        "num_clases = len(clase_dict)\n",
        "for i in range(num_clases):\n",
        "    indices = np.where(np.argmax(y_test_cat, axis=1) == i)[0]\n",
        "    if len(indices) == 0:\n",
        "        continue  # Saltar si no hay im√°genes de esa clase\n",
        "    idx = indices[0]\n",
        "\n",
        "    imagen = X_test[idx]\n",
        "    etiqueta_real = i\n",
        "\n",
        "    # Generar mapa\n",
        "    saliencia, clase_predicha = generar_mapa_saliencia_mejorado(cnn, imagen, etiqueta_real, clase_dict)\n",
        "\n",
        "    # Crear figura\n",
        "    plt.figure(figsize=(8, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(imagen)\n",
        "    plt.title(f\"Real: {clase_dict[etiqueta_real]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(imagen)\n",
        "    plt.imshow(saliencia, cmap='jet', alpha=0.55)\n",
        "    plt.title(f\"Pred: {clase_dict[clase_predicha]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Guardar imagen\n",
        "    filename = f\"{clase_dict[etiqueta_real]}_saliency.png\"\n",
        "    filepath = os.path.join(output_dir, filename)\n",
        "    plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "print(f\"‚úÖ Mapas de saliencia guardados en tu Drive en: {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lO2nU9rvHN7M",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lO2nU9rvHN7M",
        "outputId": "3ef9172b-f977-4406-bd03-e980646f0cb4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "def generar_mapa_saliencia_mejorado(modelo, imagen, etiqueta_real, clase_dict):\n",
        "    \"\"\"\n",
        "    Genera un mapa de saliencia con mejor visualizaci√≥n (tipo heatmap intensivo).\n",
        "    Retorna la imagen original y el mapa para graficarlos externamente.\n",
        "    \"\"\"\n",
        "    img_tensor = tf.convert_to_tensor(imagen[np.newaxis, ...])\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(img_tensor)\n",
        "        predicciones = modelo(img_tensor)\n",
        "        clase_predicha = tf.argmax(predicciones[0])\n",
        "        score = predicciones[:, clase_predicha]\n",
        "\n",
        "    gradientes = tape.gradient(score, img_tensor)\n",
        "    saliencia = tf.reduce_max(tf.abs(gradientes), axis=-1)[0]\n",
        "\n",
        "    # üî• Normalizaci√≥n con realce gamma (mejor contraste)\n",
        "    saliencia = (saliencia - tf.reduce_min(saliencia)) / (tf.reduce_max(saliencia) + 1e-8)\n",
        "    saliencia = tf.pow(saliencia, 0.5)\n",
        "\n",
        "    return saliencia.numpy(), int(clase_predicha)\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# üîß Mostrar una imagen aleatoria por clase (2 por fila)\n",
        "# =========================================\n",
        "\n",
        "num_clases = len(clase_dict)\n",
        "cols = 2\n",
        "rows = num_clases  # 1 fila por clase (original + saliencia)\n",
        "\n",
        "plt.figure(figsize=(10, 4 * rows))\n",
        "\n",
        "for i in range(num_clases):\n",
        "    # üîÅ Seleccionar un √≠ndice aleatorio de esa clase\n",
        "    indices_clase = np.where(np.argmax(y_test_cat, axis=1) == i)[0]\n",
        "    if len(indices_clase) == 0:\n",
        "        continue  # por si no hay muestras de esa clase en test\n",
        "    idx = np.random.choice(indices_clase)  # üëà aqu√≠ ocurre la aleatoriedad\n",
        "\n",
        "    imagen = X_test[idx]\n",
        "    etiqueta_real = i\n",
        "\n",
        "    # Generar mapa de saliencia\n",
        "    saliencia, clase_predicha = generar_mapa_saliencia_mejorado(cnn, imagen, etiqueta_real, clase_dict)\n",
        "\n",
        "    # --- Imagen original ---\n",
        "    plt.subplot(rows, cols, 2*i + 1)\n",
        "    plt.imshow(imagen)\n",
        "    plt.title(f\"Real: {clase_dict[etiqueta_real]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # --- Imagen con heatmap ---\n",
        "    plt.subplot(rows, cols, 2*i + 2)\n",
        "    plt.imshow(imagen)\n",
        "    plt.imshow(saliencia, cmap='jet', alpha=0.55)\n",
        "    plt.title(f\"Pred: {clase_dict[clase_predicha]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
